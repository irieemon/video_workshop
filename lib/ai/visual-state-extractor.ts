/**
 * Visual State Extraction
 *
 * Extracts visual state from generated video prompts for continuity propagation.
 * Uses GPT-4 to analyze prompts and extract key visual elements that must remain
 * consistent in the next segment.
 *
 * Part of Multi-Segment Video Generation Feature (Phase 2)
 */

import OpenAI from 'openai'

// ============================================================================
// Types
// ============================================================================

export interface SegmentVisualState {
  final_frame_description: string
  character_positions: Record<string, string> // character_id -> position description
  lighting_state: string
  camera_position: string
  mood_atmosphere: string
  key_visual_elements: string[]
  timestamp: string
}

export interface VisualStateExtractionOptions {
  characterIds?: string[] // Known character IDs to track
  focusAreas?: string[] // Specific areas to focus on (e.g., 'lighting', 'camera')
}

// ============================================================================
// Main Extraction Function
// ============================================================================

/**
 * Extracts visual state from a generated Sora prompt
 *
 * @param optimizedPrompt - The final Sora prompt generated by agents
 * @param options - Extraction options
 * @returns Visual state object for continuity propagation
 */
export async function extractVisualState(
  optimizedPrompt: string,
  options: VisualStateExtractionOptions = {}
): Promise<SegmentVisualState> {
  const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY,
  })

  const systemPrompt = buildExtractionSystemPrompt(options)
  const userPrompt = buildExtractionUserPrompt(optimizedPrompt, options)

  try {
    const response = await openai.chat.completions.create({
      model: 'gpt-4o-mini', // Fast and cost-effective for extraction
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userPrompt },
      ],
      response_format: { type: 'json_object' },
      temperature: 0.3, // Low temperature for consistent extraction
      max_tokens: 800,
    })

    const content = response.choices[0].message.content
    if (!content) {
      throw new Error('No content returned from OpenAI')
    }

    const extracted = JSON.parse(content)

    // Validate and structure the response
    const visualState: SegmentVisualState = {
      final_frame_description: extracted.final_frame_description || '',
      character_positions: extracted.character_positions || {},
      lighting_state: extracted.lighting_state || '',
      camera_position: extracted.camera_position || '',
      mood_atmosphere: extracted.mood_atmosphere || '',
      key_visual_elements: extracted.key_visual_elements || [],
      timestamp: new Date().toISOString(),
    }

    return visualState
  } catch (error) {
    console.error('Visual state extraction error:', error)

    // Return fallback minimal state on error
    return {
      final_frame_description: 'Unable to extract visual state from prompt',
      character_positions: {},
      lighting_state: 'Natural lighting',
      camera_position: 'Medium shot',
      mood_atmosphere: 'Neutral',
      key_visual_elements: [],
      timestamp: new Date().toISOString(),
    }
  }
}

// ============================================================================
// Prompt Building
// ============================================================================

/**
 * Builds the system prompt for extraction
 */
function buildExtractionSystemPrompt(options: VisualStateExtractionOptions): string {
  return `You are a visual continuity analyzer for video production. Your task is to extract the visual state at the END of a video segment from its prompt description.

Focus on elements that are CRITICAL for visual continuity in the next segment:
1. Final frame description - What is visible in the last moment
2. Character positions - Where each character is positioned at the end
3. Lighting state - Current lighting conditions (time of day, mood, sources)
4. Camera position - Final camera angle and framing
5. Mood/atmosphere - Overall visual tone and feeling
6. Key visual elements - Important props, objects, or environmental features

Extract information as it appears in the prompt. If something is not specified, use reasonable defaults based on context.

Return ONLY valid JSON with this structure:
{
  "final_frame_description": "string - comprehensive description of last frame",
  "character_positions": {
    "character_name_or_id": "string - position description"
  },
  "lighting_state": "string - lighting conditions",
  "camera_position": "string - camera angle and framing",
  "mood_atmosphere": "string - overall visual tone",
  "key_visual_elements": ["array", "of", "important", "visual", "elements"]
}

Be specific and actionable - the next segment's prompt will use this information to maintain continuity.`
}

/**
 * Builds the user prompt with the optimized prompt to analyze
 */
function buildExtractionUserPrompt(
  optimizedPrompt: string,
  options: VisualStateExtractionOptions
): string {
  let prompt = `Extract the visual state from the end of this video segment prompt:\n\n`
  prompt += `SEGMENT PROMPT:\n${optimizedPrompt}\n\n`

  if (options.characterIds && options.characterIds.length > 0) {
    prompt += `KNOWN CHARACTERS TO TRACK:\n`
    options.characterIds.forEach((id) => {
      prompt += `- ${id}\n`
    })
    prompt += `\n`
  }

  if (options.focusAreas && options.focusAreas.length > 0) {
    prompt += `FOCUS AREAS:\n`
    options.focusAreas.forEach((area) => {
      prompt += `- ${area}\n`
    })
    prompt += `\n`
  }

  prompt += `Extract the visual state as it would appear at the END of this segment.`

  return prompt
}

// ============================================================================
// Context Building for Next Segment
// ============================================================================

/**
 * Builds context text for next segment from extracted visual state
 *
 * @param visualState - Extracted visual state from previous segment
 * @returns Formatted context string for injection into next segment's prompt
 */
export function buildContinuityContext(visualState: SegmentVisualState): string {
  let context = `=== VISUAL CONTINUITY FROM PREVIOUS SEGMENT ===\n\n`

  // Final frame description
  context += `PREVIOUS SEGMENT ENDED WITH:\n${visualState.final_frame_description}\n\n`

  // Character positions
  if (Object.keys(visualState.character_positions).length > 0) {
    context += `CHARACTER POSITIONS:\n`
    for (const [character, position] of Object.entries(visualState.character_positions)) {
      context += `- ${character}: ${position}\n`
    }
    context += `\n`
  }

  // Lighting state
  context += `LIGHTING: ${visualState.lighting_state}\n`

  // Camera position
  context += `CAMERA: ${visualState.camera_position}\n`

  // Mood/atmosphere
  context += `MOOD/ATMOSPHERE: ${visualState.mood_atmosphere}\n`

  // Key visual elements
  if (visualState.key_visual_elements.length > 0) {
    context += `\nKEY VISUAL ELEMENTS TO MAINTAIN:\n`
    visualState.key_visual_elements.forEach((element) => {
      context += `- ${element}\n`
    })
  }

  context += `\nCRITICAL: Maintain visual continuity with these elements unless the narrative explicitly requires a change. If changes occur, ensure smooth transitions.\n`
  context += `\n=== END CONTINUITY CONTEXT ===\n\n`

  return context
}

// ============================================================================
// Batch Extraction
// ============================================================================

/**
 * Extracts visual states for multiple segments in parallel
 *
 * @param prompts - Array of optimized prompts
 * @param options - Extraction options
 * @returns Array of visual states
 */
export async function batchExtractVisualStates(
  prompts: { segmentId: string; prompt: string }[],
  options: VisualStateExtractionOptions = {}
): Promise<Array<{ segmentId: string; visualState: SegmentVisualState }>> {
  const extractions = prompts.map(async ({ segmentId, prompt }) => {
    const visualState = await extractVisualState(prompt, options)
    return { segmentId, visualState }
  })

  return Promise.all(extractions)
}

// ============================================================================
// Validation Helpers
// ============================================================================

/**
 * Checks if visual state is valid and has sufficient information
 */
export function isVisualStateValid(state: SegmentVisualState): boolean {
  return (
    state.final_frame_description.length > 20 &&
    state.lighting_state.length > 0 &&
    state.camera_position.length > 0
  )
}

/**
 * Merges multiple visual states (for anchor point refresh)
 */
export function mergeVisualStates(states: SegmentVisualState[]): SegmentVisualState {
  if (states.length === 0) {
    throw new Error('Cannot merge empty visual states array')
  }

  if (states.length === 1) {
    return states[0]
  }

  // Use the most recent state as base
  const latest = states[states.length - 1]

  // Merge character positions (prefer most recent)
  const mergedPositions: Record<string, string> = {}
  states.forEach((state) => {
    Object.assign(mergedPositions, state.character_positions)
  })

  // Collect all key visual elements (deduplicated)
  const allElements = new Set<string>()
  states.forEach((state) => {
    state.key_visual_elements.forEach((elem) => allElements.add(elem))
  })

  return {
    ...latest,
    character_positions: mergedPositions,
    key_visual_elements: Array.from(allElements),
  }
}
